{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bu0ai/anaconda3/envs/shiba/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from dotenv import load_dotenv\n",
    "from src.utils import *\n",
    "from src.utils_azure import *\n",
    "load_dotenv('/mnt/d/docker_volume/room_of_nhanhuynh/ai_butler/CAD-ShibaSangyo/official/.env')\n",
    "\n",
    "\n",
    "\n",
    "endpoint = os.environ['AZURE_SHIBA_ENDPOINT_KEY']\n",
    "subscription_key = os.environ['AZURE_SHIBA_SUBSCRIPTION_KEY']\n",
    "COMPUTERVISION_CLIENT = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/docker_volume/room_of_nhanhuynh/ai_butler/CAD-ShibaSangyo/full_build_from_scratch_nhanhuynh/src/utils_azure.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  match_builder_name.sort_values(by='top', inplace=True)\n",
      "/mnt/d/docker_volume/room_of_nhanhuynh/ai_butler/CAD-ShibaSangyo/full_build_from_scratch_nhanhuynh/src/utils_azure.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  match_anken.sort_values(by='top', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "image_path = '/mnt/d/docker_volume/room_of_nhanhuynh/ai_butler/CAD-ShibaSangyo/data_label/sample-03.png'\n",
    "det_draw_path = r'/mnt/d/docker_volume/room_of_nhanhuynh/ai_butler/CAD-ShibaSangyo/demo/weight/draw_231229/best.pt'\n",
    "det_code_path = r'/mnt/d/docker_volume/room_of_nhanhuynh/ai_butler/CAD-ShibaSangyo/demo/weight/code_231207/best.pt'\n",
    "\n",
    "\n",
    "det_draw_model = load_yolo(det_draw_path)\n",
    "det_code_model = load_yolo(det_code_path)\n",
    "raw_image_pil = load_image(image_path)\n",
    "result_draw_df = yolo_inference(raw_image_pil, det_draw_model, type='draw')\n",
    "raw_code_df = yolo_inference(raw_image_pil, det_code_model, type='code')\n",
    "base_image_pil, draw_location_list = split_images(raw_image_pil.copy(), result_draw_df)\n",
    "basic_info_dict = get_basic_info(base_image_pil, COMPUTERVISION_CLIENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing cache to delete\n",
      "Nothing cache to delete\n"
     ]
    }
   ],
   "source": [
    "code_df = raw_code_df[raw_code_df.boxes.apply(lambda b: calc_ovl(b, [803, 1169, 2478, 2944]) > 0.5)]\n",
    "code_df.reset_index(drop=True, inplace=True)\n",
    "num_cell, cell_width, cell_height = get_cell_size(code_df)\n",
    "clear_cache_last_session('/mnt/d/docker_volume/room_of_nhanhuynh/ai_butler/CAD-ShibaSangyo/full_build_from_scratch_nhanhuynh/tmpFile/tmp_core/')\n",
    "clear_cache_last_session('/mnt/d/docker_volume/room_of_nhanhuynh/ai_butler/CAD-ShibaSangyo/full_build_from_scratch_nhanhuynh/tmpFile/tmp_gen_grid/')\n",
    "concat_image_pil = gen_grid_image(raw_image_pil, code_df, num_cell, cell_width, cell_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 4, 61, 29],\n",
       " [374, 9, 404, 36],\n",
       " [1121, 13, 1134, 38],\n",
       " [194, 14, 234, 38],\n",
       " [564, 15, 583, 36],\n",
       " [742, 12, 765, 35],\n",
       " [919, 9, 947, 37],\n",
       " [18, 34, 51, 57],\n",
       " [206, 46, 225, 67],\n",
       " [383, 41, 408, 63],\n",
       " [567, 44, 582, 63],\n",
       " [737, 41, 763, 65],\n",
       " [924, 41, 953, 65],\n",
       " [1094, 45, 1162, 69],\n",
       " [15, 65, 50, 85],\n",
       " [185, 73, 241, 95],\n",
       " [367, 71, 421, 93],\n",
       " [546, 72, 599, 95],\n",
       " [728, 71, 781, 93],\n",
       " [907, 70, 965, 93],\n",
       " [6, 125, 61, 148],\n",
       " [184, 122, 239, 145],\n",
       " [386, 129, 412, 152],\n",
       " [565, 132, 592, 149],\n",
       " [730, 125, 770, 146],\n",
       " [922, 120, 978, 144],\n",
       " [1107, 127, 1131, 154],\n",
       " [21, 154, 48, 177],\n",
       " [199, 152, 226, 174],\n",
       " [390, 160, 407, 182],\n",
       " [564, 154, 613, 179],\n",
       " [737, 156, 768, 178],\n",
       " [908, 152, 1005, 178],\n",
       " [1109, 161, 1129, 182],\n",
       " [15, 184, 47, 206],\n",
       " [195, 182, 224, 203],\n",
       " [368, 189, 423, 212],\n",
       " [550, 187, 605, 211],\n",
       " [937, 183, 963, 206],\n",
       " [1092, 188, 1147, 212],\n",
       " [16, 247, 47, 268],\n",
       " [192, 246, 222, 266],\n",
       " [372, 244, 527, 270],\n",
       " [557, 241, 598, 274],\n",
       " [729, 240, 784, 264],\n",
       " [911, 242, 981, 266],\n",
       " [1097, 242, 1153, 264],\n",
       " [23, 279, 41, 300],\n",
       " [203, 278, 217, 298],\n",
       " [440, 280, 461, 300],\n",
       " [746, 271, 765, 293],\n",
       " [926, 273, 959, 297],\n",
       " [1097, 271, 1153, 293],\n",
       " [3, 304, 60, 329],\n",
       " [182, 301, 240, 324],\n",
       " [557, 282, 596, 303],\n",
       " [549, 313, 602, 336],\n",
       " [739, 297, 772, 319],\n",
       " [1109, 299, 1140, 322],\n",
       " [16, 361, 42, 386],\n",
       " [199, 362, 231, 389],\n",
       " [379, 366, 407, 384],\n",
       " [569, 363, 599, 392],\n",
       " [726, 356, 782, 381],\n",
       " [908, 355, 968, 380],\n",
       " [1093, 358, 1149, 384],\n",
       " [12, 392, 60, 414],\n",
       " [207, 394, 226, 417],\n",
       " [370, 394, 413, 416],\n",
       " [548, 397, 616, 420],\n",
       " [748, 388, 762, 408],\n",
       " [931, 388, 959, 410],\n",
       " [1112, 391, 1127, 409],\n",
       " [2, 420, 56, 444],\n",
       " [189, 422, 243, 446],\n",
       " [367, 422, 419, 445],\n",
       " [737, 412, 771, 439],\n",
       " [924, 416, 953, 438],\n",
       " [1105, 415, 1132, 439],\n",
       " [18, 482, 47, 503],\n",
       " [203, 479, 233, 505],\n",
       " [366, 481, 399, 511],\n",
       " [560, 481, 597, 505],\n",
       " [744, 479, 772, 504],\n",
       " [920, 485, 950, 505],\n",
       " [1101, 473, 1122, 497],\n",
       " [16, 509, 45, 532],\n",
       " [208, 512, 222, 531],\n",
       " [373, 513, 392, 536],\n",
       " [569, 514, 603, 537],\n",
       " [750, 509, 768, 530],\n",
       " [915, 514, 957, 536],\n",
       " [1091, 504, 1124, 527],\n",
       " [2, 539, 59, 562],\n",
       " [188, 539, 243, 563],\n",
       " [549, 540, 605, 563],\n",
       " [732, 539, 785, 560],\n",
       " [6, 597, 77, 619],\n",
       " [198, 592, 213, 615],\n",
       " [381, 595, 413, 623],\n",
       " [557, 589, 575, 611],\n",
       " [918, 593, 948, 626],\n",
       " [27, 630, 55, 653],\n",
       " [188, 624, 224, 646],\n",
       " [361, 624, 411, 648],\n",
       " [551, 617, 583, 638],\n",
       " [739, 602, 773, 624],\n",
       " [739, 628, 789, 651],\n",
       " [363, 654, 422, 682],\n",
       " [727, 658, 784, 682]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_words, draw_boxes = ocr_azure_cad(concat_image_pil.copy(), COMPUTERVISION_CLIENT)\n",
    "draw_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(draw_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dict = mapping_code(raw_image_pil, draw_words, draw_boxes, code_df,\n",
    "                                    num_cell, cell_width, cell_height)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shiba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
